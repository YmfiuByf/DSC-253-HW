{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07b654f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "D:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "from math import log\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3df207a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "nyt_path = r\"C:\\Users\\DELL\\Desktop\\DSC 253\\HW-1\\HW-1\\nyt.csv\"\n",
    "ag_path = r\"C:\\Users\\DELL\\Desktop\\DSC 253\\HW-1\\HW-1\\ag.csv\"\n",
    "nyt_df = pd.read_csv(nyt_path)\n",
    "ag_df = pd.read_csv(ag_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "003066e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(reuters) - carlos tevez sealed his move to ju...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if professional pride and strong defiance can ...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>palermo, sicily — roberta vinci beat top-seede...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spain's big two soccer teams face a pair of it...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the argentine soccer club san lorenzo complete...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   label\n",
       "0  (reuters) - carlos tevez sealed his move to ju...  sports\n",
       "1  if professional pride and strong defiance can ...  sports\n",
       "2  palermo, sicily — roberta vinci beat top-seede...  sports\n",
       "3  spain's big two soccer teams face a pair of it...  sports\n",
       "4  the argentine soccer club san lorenzo complete...  sports"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af86cab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'some', 'but', \"she's\", 'wasn', 'their', 'a', 'at', 'has', \"should've\", 'under', 'with', 're', 'an', \"shan't\", 'off', 'during', 'after', 'as', \"you'll\", 'yourselves', 'yours', 'his', 'are', 'who', 'when', 'yourself', \"couldn't\", 'didn', 'that', 'aren', 'needn', 'weren', 'than', 'same', 'where', 'just', 'couldn', 'ourselves', 't', \"won't\", 'haven', 'not', 'very', 'which', 'being', 'o', 'we', 'doing', 'again', 'then', 'own', 'himself', 'between', 'while', 'him', \"shouldn't\", \"weren't\", 'and', 'over', 'won', 'don', 'to', 'it', 'i', 'he', 'its', 'the', \"didn't\", \"wouldn't\", 'if', 'both', 'my', 'most', 'before', 'below', 'will', 'those', 'isn', 'up', 'about', 'y', 'wouldn', 'there', 'each', 'myself', 'd', 'into', 'too', \"you're\", 'because', 'through', 'hasn', 'had', 'hadn', 'ours', 'this', 'on', 'so', 'whom', 'does', \"hasn't\", 'ma', \"don't\", 'more', 'only', 'them', \"haven't\", 'did', \"it's\", \"hadn't\", 'mightn', 'further', \"you've\", 'against', 'our', 'was', 'can', 'll', 'such', \"that'll\", 'you', 'these', 'shan', 'been', 'hers', 'no', 'of', 'other', 'in', 'were', 'do', 'herself', \"needn't\", 'now', 'any', 'her', 'itself', 'until', \"wasn't\", 'should', \"you'd\", 'your', 'theirs', 'all', 'have', 'mustn', 'am', 'why', 'they', 'is', 'once', \"isn't\", 'how', 'out', 've', 'nor', 's', 'doesn', 'or', 'by', 'here', 'what', 'few', 'having', 'she', 'from', \"aren't\", \"mightn't\", 'down', 'm', 'themselves', \"mustn't\", 'above', \"doesn't\", 'be', 'ain', 'for', 'shouldn', 'me'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# download nltk packages and get stopwords\n",
    "import nltk\n",
    "nltk.download('punkt') \n",
    "nltk.download('stopwords') \n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56601fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define preprocessing function\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import PorterStemmer \n",
    "\n",
    "ps = PorterStemmer() \n",
    "\n",
    "# return a list of tokens\n",
    "def pre_processing_by_nltk(doc, stemming = True, need_sent = False):\n",
    "    # step 1: get sentences\n",
    "    sentences = sent_tokenize(doc)\n",
    "    # step 2: get tokens\n",
    "    tokens = []\n",
    "    for sent in sentences:\n",
    "        words = word_tokenize(sent)\n",
    "        # step 3: stemming\n",
    "        if stemming:\n",
    "            words = [ps.stem(word) for word in words if word.lower() not in stop]\n",
    "        else:\n",
    "            words = [word for word in words if word.lower() not in stop]\n",
    "        if need_sent:\n",
    "            tokens.append(words)\n",
    "        else:\n",
    "            tokens += words\n",
    "    return [w.lower() for w in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9290ea37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 11519/11519 [02:43<00:00, 70.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# Compute token frequency over the corpus, prepare for the next step\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "DF = defaultdict(float)\n",
    "for doc in tqdm(nyt_df.text):\n",
    "    tokens = pre_processing_by_nltk(doc)\n",
    "    for token in set(tokens):\n",
    "        DF[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa5edad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123888 5987\n"
     ]
    }
   ],
   "source": [
    "# Construct IDF and vocabulary dictionary\n",
    "\n",
    "IDF, vocab = dict(), dict()\n",
    "for token in DF:\n",
    "    if DF[token] < 50:\n",
    "        # this becomes an unk\n",
    "        pass\n",
    "    else:\n",
    "        vocab[token] = len(vocab) # gives an ID to the token\n",
    "        IDF[token] = 1 + log(len(nyt_df.text) / DF[token])\n",
    "\n",
    "# Add unk token to vocab\n",
    "IDF['<UNK>'] = 1\n",
    "vocab['<UNK>'] = len(vocab)\n",
    "print(len(DF), len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cfd037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define preprocessing function\n",
    "\n",
    "def tfidf_feature_extractor(doc, vocab, IDF):\n",
    "    tokens = pre_processing_by_nltk(doc)\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token not in vocab:\n",
    "            tokens[i] = '<UNK>'\n",
    "    TF = defaultdict(int)\n",
    "    for token in tokens:\n",
    "        TF[token] += 1\n",
    "    x = [0] * len(vocab)\n",
    "    for token in set(tokens):\n",
    "        tfidf = log(TF[token] + 1) * IDF[token]\n",
    "        token_id = vocab[token]\n",
    "#         print(token, TF[token], IDF[token])\n",
    "        x[token_id] = tfidf # this will be a dense matrix\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0f87ee98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 11519/11519 [05:26<00:00, 35.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extract feature for binary-x1, Frequency-x2, TF-IDF-x3\n",
    "\n",
    "x1,x2,x3 = [],[],[]\n",
    "for doc in tqdm(nyt_df.text):\n",
    "    tokens = pre_processing_by_nltk(doc)\n",
    "    v1,v2 = [0]*len(vocab),[0]*len(vocab)\n",
    "    for token in tokens:\n",
    "        if token not in vocab:\n",
    "            v1[-1] = 1\n",
    "            v2[-1] += 1\n",
    "        else:\n",
    "            i = vocab[token]\n",
    "            v1[i] = 1\n",
    "            v2[i] += 1\n",
    "    v3 = tfidf_feature_extractor(doc, vocab, IDF)\n",
    "    x1.append(v1)\n",
    "    x2.append(v2)\n",
    "    x3.append(v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4df2bb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = nyt_df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f17de97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "x1_train,x1_test_val,y1_train,y1_test_val = train_test_split(x1,y,test_size=0.2,random_state=42)\n",
    "x1_test,x1_val,y1_test,y1_val = train_test_split(x1_test_val,y1_test_val,test_size=0.5,random_state=42)\n",
    "\n",
    "x2_train,x2_test_val,y2_train,y2_test_val = train_test_split(x2,y,test_size=0.2,random_state=42)\n",
    "x2_test,x2_val,y2_test,y2_val = train_test_split(x2_test_val,y2_test_val,test_size=0.5,random_state=42)\n",
    "\n",
    "x3_train,x3_test_val,y3_train,y3_test_val = train_test_split(x3,y,test_size=0.2,random_state=42)\n",
    "x3_test,x3_val,y3_test,y3_val = train_test_split(x3_test_val,y3_test_val,test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c79c5081",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.7min remaining:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.7min finished\n"
     ]
    }
   ],
   "source": [
    "# Train model for (a) Binary\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "clf1 = LogisticRegressionCV(cv=5,\n",
    "                           scoring='accuracy',\n",
    "                           random_state=42,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=3,\n",
    "                           max_iter=300).fit(x1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b90ed5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  7.4min remaining: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  7.5min finished\n",
      "D:\\Anaconda\\envs\\pytorch\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train model for (b) Frequency\n",
    "clf2 = LogisticRegressionCV(cv=5,\n",
    "                           scoring='accuracy',\n",
    "                           random_state=42,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=3,\n",
    "                           max_iter=300).fit(x2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "abd60253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  2.1min remaining:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  2.3min finished\n"
     ]
    }
   ],
   "source": [
    "# Train model for (c) TF-IDF\n",
    "clf3 = LogisticRegressionCV(cv=5,\n",
    "                           scoring='accuracy',\n",
    "                           random_state=42,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=3,\n",
    "                           max_iter=300).fit(x3_train, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5933457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze function\n",
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "def analyze(clf,x_test,y_test):\n",
    "    y_pred = clf.predict(x_test)\n",
    "    f1_macro = f1_score(y_test,y_pred,average='macro')\n",
    "    f1_micro = f1_score(y_test,y_pred,average='micro')\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    print(f\"accuracy={accuracy:.3f}, macro f1={f1_macro:.3f}, micro f1={f1_micro:.3f}\")\n",
    "    return accuracy,f1_macro,f1_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7d287833",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_res = pd.DataFrame(columns=['Accuracy','Macro F1','Micro F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e522ac9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.9835069444444444, macro f1=0.961933235988707, micro f1=0.9835069444444444\n"
     ]
    }
   ],
   "source": [
    "q1_res.loc['Binary']=analyze(clf1,x1_test,y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f88e0ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.9869791666666666, macro f1=0.9700064581976999, micro f1=0.9869791666666666\n"
     ]
    }
   ],
   "source": [
    "q1_res.loc['Frequency']=analyze(clf2,x2_test,y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "05a86a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.9826388888888888, macro f1=0.9587116733191015, micro f1=0.9826388888888888\n"
     ]
    }
   ],
   "source": [
    "q1_res.loc['TF-IDF']=analyze(clf3,x3_test,y3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c89acb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Micro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Binary</th>\n",
       "      <td>0.983507</td>\n",
       "      <td>0.961933</td>\n",
       "      <td>0.983507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frequency</th>\n",
       "      <td>0.986979</td>\n",
       "      <td>0.970006</td>\n",
       "      <td>0.986979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TF-IDF</th>\n",
       "      <td>0.982639</td>\n",
       "      <td>0.958712</td>\n",
       "      <td>0.982639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Accuracy  Macro F1  Micro F1\n",
       "Binary     0.983507  0.961933  0.983507\n",
       "Frequency  0.986979  0.970006  0.986979\n",
       "TF-IDF     0.982639  0.958712  0.982639"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d421fc42",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "\n",
    "All three methods achieve pretty well performance (Above 98% accuracy). Besides, we can also observe that both Frequency and TF-IDF features slightly outperform Binary feature, because they encode more information: Frequency and TF-IDF take into account the number of occurance of a word, whereas Binary feature only considers the presence of word in a document.\n",
    "Also, the fact that Frequency has slightly better performance than TF-IDF suggests that more complicated feature does not always imply better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a29507d",
   "metadata": {},
   "source": [
    "# 2.Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87645fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_5452\\2111455119.py:9: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  _ = glove2word2vec(glove_file, tmp_file)\n"
     ]
    }
   ],
   "source": [
    "# using publicly available pre-trained Glove embeddings as word vector\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_file = r\"C:\\Users\\DELL\\Desktop\\DSC 253\\glove.6B\\glove.6B.100d.txt\"\n",
    "tmp_file = get_tmpfile(\"test_word2vec.txt\")\n",
    "\n",
    "_ = glove2word2vec(glove_file, tmp_file)\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0173b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Train Word2Vec (using gensim package) on AGNews/NYT text data\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.stem import PorterStemmer \n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('stopwords') # <--- this is new\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "ps = PorterStemmer() \n",
    "\n",
    "def pre_processing_by_nltk(doc, stemming = True, need_sent = False):\n",
    "    # step 1: get sentences\n",
    "    sentences = sent_tokenize(doc)\n",
    "    # step 2: get tokens\n",
    "    tokens = []\n",
    "    for sent in sentences:\n",
    "        words = word_tokenize(sent)\n",
    "        # step 3 (optional): stemming\n",
    "        if stemming:\n",
    "            words = [ps.stem(word) for word in words if word.lower() not in stop]\n",
    "        else:\n",
    "            words = [word for word in words if word.lower() not in stop]\n",
    "        if need_sent:\n",
    "            tokens.append(words)\n",
    "        else:\n",
    "            tokens += words\n",
    "    return [w.lower() for w in tokens]\n",
    "\n",
    "\n",
    "ag_path = r\"C:\\Users\\DELL\\Desktop\\DSC 253\\HW-1\\HW-1\\ag.csv\"\n",
    "nyt_path = r\"C:\\Users\\DELL\\Desktop\\DSC 253\\HW-1\\HW-1\\nyt.csv\"\n",
    "ag_df = pd.read_csv(ag_path)\n",
    "ag_df['tokens'] = ag_df['text'].apply(pre_processing_by_nltk)\n",
    "nyt_df = pd.read_csv(nyt_path)\n",
    "nyt_df['tokens'] = nyt_df['text'].apply(pre_processing_by_nltk)\n",
    "\n",
    "word2vec_model_ag = Word2Vec(sentences=ag_df['tokens'], vector_size=100, window=5, min_count=2, sg=1, workers=4)\n",
    "word2vec_model_nyt = Word2Vec(sentences=nyt_df['tokens'], vector_size=100, window=5, min_count=2, sg=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b731cb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute document vectors by averaging word vectors\n",
    "def document_vector(tokens,word2vec_model):\n",
    "    valid_words = [word for word in tokens if word in word2vec_model.wv]\n",
    "    if valid_words:\n",
    "        return np.mean(word2vec_model.wv[valid_words], axis=0)\n",
    "    else:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "def document_vector_ag(tokens):\n",
    "    return document_vector(tokens,word2vec_model_ag)\n",
    "\n",
    "def document_vector_nyt(tokens):\n",
    "    return document_vector(tokens,word2vec_model_nyt)\n",
    "    \n",
    "def document_vector_glove(tokens):\n",
    "    valid_words = [word for word in tokens if word in model]\n",
    "    if valid_words:\n",
    "        return np.mean(model[valid_words], axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "    \n",
    "# Compute document vectors for all documents\n",
    "nyt_df['doc_vector_ag'] = nyt_df['tokens'].apply(document_vector_ag)\n",
    "nyt_df['doc_vector_nyt'] = nyt_df['tokens'].apply(document_vector_nyt)\n",
    "nyt_df['doc_vector_glove'] = nyt_df['tokens'].apply(document_vector_glove)\n",
    "\n",
    "# Extract features and labels for further use\n",
    "x_ag = np.vstack(nyt_df['doc_vector_ag'].values)\n",
    "x_nyt = np.vstack(nyt_df['doc_vector_nyt'].values)\n",
    "x_glove = np.vstack(nyt_df['doc_vector_glove'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99e37017",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train,X1_test_val,Y1_train,Y1_test_val = train_test_split(x_glove,y,test_size=0.2,random_state=42)\n",
    "X1_test,X1_val,Y1_test,Y1_val = train_test_split(X1_test_val,Y1_test_val,test_size=0.5,random_state=42)\n",
    "\n",
    "X2_train,X2_test_val,Y2_train,Y2_test_val = train_test_split(x_ag,y,test_size=0.2,random_state=42)\n",
    "X2_test,X2_val,Y2_test,Y2_val = train_test_split(X2_test_val,Y2_test_val,test_size=0.5,random_state=42)\n",
    "\n",
    "X3_train,X3_test_val,Y3_train,Y3_test_val = train_test_split(x_nyt,y,test_size=0.2,random_state=42)\n",
    "X3_test,X3_val,Y3_test,Y3_val = train_test_split(X3_test_val,Y3_test_val,test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a049bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    6.5s remaining:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    7.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "CLF1 = LogisticRegressionCV(cv=5,\n",
    "                           scoring='accuracy',\n",
    "                           random_state=42,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=3,\n",
    "                           max_iter=300).fit(X1_train, Y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77759b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    6.4s remaining:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.7s finished\n"
     ]
    }
   ],
   "source": [
    "CLF2 = LogisticRegressionCV(cv=5,\n",
    "                           scoring='accuracy',\n",
    "                           random_state=42,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=3,\n",
    "                           max_iter=300).fit(X2_train, Y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bd2319b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    6.5s remaining:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    6.7s finished\n"
     ]
    }
   ],
   "source": [
    "CLF3 = LogisticRegressionCV(cv=5,\n",
    "                           scoring='accuracy',\n",
    "                           random_state=42,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=3,\n",
    "                           max_iter=300).fit(X3_train, Y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b773c544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.980, macro f1=0.952, micro f1=0.980\n"
     ]
    }
   ],
   "source": [
    "q2_df = pd.DataFrame(columns=['Accuracy','Macro F1','Micro F1'])\n",
    "q2_df.loc['Glove'] = analyze(CLF1,X1_test,Y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ac2d767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.979, macro f1=0.952, micro f1=0.979\n"
     ]
    }
   ],
   "source": [
    "q2_df.loc['Word2Vec AGNews'] = analyze(CLF2,X2_test,Y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "244e2840",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.984, macro f1=0.961, micro f1=0.984\n"
     ]
    }
   ],
   "source": [
    "q2_df.loc['Word2Vec NYT'] = analyze(CLF3,X3_test,Y3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2a566a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Micro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Glove</th>\n",
       "      <td>0.980035</td>\n",
       "      <td>0.952107</td>\n",
       "      <td>0.980035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word2Vec AGNews</th>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.951996</td>\n",
       "      <td>0.979167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word2Vec NYT</th>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.961177</td>\n",
       "      <td>0.984375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Accuracy  Macro F1  Micro F1\n",
       "Glove            0.980035  0.952107  0.980035\n",
       "Word2Vec AGNews  0.979167  0.951996  0.979167\n",
       "Word2Vec NYT     0.984375  0.961177  0.984375"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6955fbc3",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "\n",
    "(a) Word2Vec trained on NYT performs the best across all metrics. This is expected since the Word2Vec model was trained specifically on the NYT dataset, which matches the domain of the test set. The word vectors are highly tailored to this particular dataset, making them more effective in capturing the nuances of the text. \n",
    "Pre-trained GloVe embeddings also perform very well, but slightly below (iii). GloVe embeddings are trained on a large, diverse corpus, which allows them to generalize well across a wide range of tasks. However, because they are not specifically tuned to the NYT dataset, they fall slightly behind the NYT-specific Word2Vec vectors in performance.\n",
    "Word2Vec trained on AGNews shows slightly lower performance compared to (i) and (iii). Since the model is trained on a different domain (AGNews) than the NYT test set, the word vectors may not capture the context and language patterns as effectively for this task. Therefore, its performance is slightly lower compared to both the general-purpose GloVe embeddings and the NYT-specific Word2Vec embeddings.\n",
    "\n",
    "(b) Disadvantages: Firstly, averaging does not preserve the word order or capture important syntactic structures, which can be crucial for understanding the meaning of a sentence.Besides, averaging treats all words equally, without accounting for the varying importance of words in a document. Rare or contextually significant words are given the same weight as common or less important ones.\n",
    "Idea to Overcome:\n",
    "For the second disadvantage, one idea to overcome is to use a weighted averaging approach where each word's vector is weighted by its importance in the document, such as TF-IDF. In this case, words that are more relevant to the document have a higher influence on the final vector. This can balance the contribution of frequent words versus rare, but contextually important words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a99308f",
   "metadata": {},
   "source": [
    "# 3.BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "82855572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.036823272705078125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Downloading vocab.txt",
       "rate": null,
       "total": 231508,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25cd133418034a0091aca23eb59131a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.04321599006652832,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Downloading tokenizer_config.json",
       "rate": null,
       "total": 48,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f8bd88e4ce485b9f9a63615b2d4802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.037830352783203125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Downloading config.json",
       "rate": null,
       "total": 570,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87747d86f704038b9d8fc372cbb7124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02642512321472168,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "Downloading pytorch_model.bin",
       "rate": null,
       "total": 440473133,
       "unit": "B",
       "unit_divisor": 1024,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4da503d8db748e6b706d5eaa9dd2abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from transformers import get_scheduler\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load pretrained tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(nyt_df.label.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cd5ce96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert label from string to int\n",
    "label_dic = dict()\n",
    "for i,label in enumerate(nyt_df.label.unique()):\n",
    "    label_dic[label] = i\n",
    "nyt_df['label'] = nyt_df['label'].apply(lambda x:label_dic[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9b77701d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.042098283767700195,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 12,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6acf5407b4343ee9afd5cd552725606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenization\n",
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_pandas(nyt_df[['text','label']])\n",
    "def tokenize_function(df):\n",
    "    return tokenizer(df['text'], padding='max_length', truncation=True, max_length=64)\n",
    "\n",
    "tokenized_datasets_raw = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c41666c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Dataset into train, test, validation\n",
    "from datasets import DatasetDict\n",
    "train_testvalid = tokenized_datasets_raw.train_test_split(test_size=0.2)\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5)\n",
    "tokenized_datasets = DatasetDict({\n",
    "'train': train_testvalid['train'],\n",
    "'test': test_valid['test'],\n",
    "'valid': test_valid['train']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "129e98a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': Value(dtype='string', id=None), 'label': Value(dtype='int64', id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets['train'].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce3bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataloader for the convience of training\n",
    "tokenized_datasets.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "train_dataloader = DataLoader(tokenized_datasets['train'], batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(tokenized_datasets['test'], batch_size=16)\n",
    "\n",
    "# use GPU if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer and scheduler setup\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(name='linear', optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}  # Move batch to device\n",
    "        outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], labels=batch['label'])\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0e178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function to compute accuracy, macro F1, and micro F1\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    true_labels, predictions = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], labels=batch['label'])\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(batch['label'].cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    macro_f1 = f1_score(true_labels, predictions, average='macro')\n",
    "    micro_f1 = f1_score(true_labels, predictions, average='micro')\n",
    "\n",
    "    return accuracy, macro_f1, micro_f1\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy, macro_f1, micro_f1 = evaluate(model, test_dataloader)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Macro F1-Score: {macro_f1:.3f}\")\n",
    "print(f\"Micro F1-Score: {micro_f1:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
